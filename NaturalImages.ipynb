{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NaturalImages.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JC5IOfmYiGc",
        "outputId": "ceae9235-f3a7-47be-f0da-26a887eebd94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_datasets as tfds\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip drive/\"My Drive\"/ArchiveNI.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeRTyC1MZP6d",
        "outputId": "037dd87e-9422-4dde-cd1c-695b93d6892b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/My Drive/ArchiveNI.zip\n",
            "replace data/natural_images/airplane/airplane_0000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitfolders.ratio('/content/natural_images', output=\"splitnaturalimages\", seed=1337, ratio=(0.7, 0.2,0.1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjQ2ZFOugfWp",
        "outputId": "0282927e-46be-4050-f6de-ada99e632a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 6899 files [00:04, 1481.13 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/splitnaturalimages/train', # This is the source directory for training images\n",
        "        target_size=(224, 224), #All images will be resized to 224*224\n",
        "        batch_size=64,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                 horizontal_flip=True,\n",
        "                                 vertical_flip=True)\n",
        "\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/content/splitnaturalimages/val',  # This is the source directory for validation images\n",
        "        target_size=(224, 224),  # All images will be resized to 224*224\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255,\n",
        "                                  rotation_range=40,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  vertical_flip=True)\n",
        "\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/splitnaturalimages/test',  # This is the source directory for test images\n",
        "        target_size=(224, 224),  # All images will be resized to 224*224\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIwgaCauiqr0",
        "outputId": "647b9bcc-4577-4598-9064-9cf093499c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4826 images belonging to 8 classes.\n",
            "Found 1377 images belonging to 8 classes.\n",
            "Found 696 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_generator.class_indices\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OFAbXrxj9Bm",
        "outputId": "f87ffa84-8e36-463f-ace1-f85060238d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'airplane': 0, 'car': 1, 'cat': 2, 'dog': 3, 'flower': 4, 'fruit': 5, 'motorbike': 6, 'person': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu',\n",
        "                           input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu',\n",
        "                           input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(8, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "BzReJdv0kgPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqbpbGbFqGvj",
        "outputId": "611c853b-c9a6-4e96-a6e7-fd6a55406fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      validation_data = validation_generator,\n",
        "      epochs=40,\n",
        "      steps_per_epoch=47,\n",
        "      validation_steps=40,\n",
        "      verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8ldoyPSqKM9",
        "outputId": "de35f3bc-c28f-42ae-841c-510781d8c54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "47/47 - 123s - loss: 2.0597 - accuracy: 0.3051 - val_loss: 1.3876 - val_accuracy: 0.5398 - 123s/epoch - 3s/step\n",
            "Epoch 2/40\n",
            "47/47 - 122s - loss: 1.3954 - accuracy: 0.4894 - val_loss: 1.1645 - val_accuracy: 0.5727 - 122s/epoch - 3s/step\n",
            "Epoch 3/40\n",
            "47/47 - 121s - loss: 1.1851 - accuracy: 0.5902 - val_loss: 0.9052 - val_accuracy: 0.6586 - 121s/epoch - 3s/step\n",
            "Epoch 4/40\n",
            "47/47 - 120s - loss: 1.0153 - accuracy: 0.6401 - val_loss: 0.9769 - val_accuracy: 0.6492 - 120s/epoch - 3s/step\n",
            "Epoch 5/40\n",
            "47/47 - 121s - loss: 0.9418 - accuracy: 0.6609 - val_loss: 0.8419 - val_accuracy: 0.7023 - 121s/epoch - 3s/step\n",
            "Epoch 6/40\n",
            "47/47 - 120s - loss: 0.8577 - accuracy: 0.6936 - val_loss: 0.7297 - val_accuracy: 0.7484 - 120s/epoch - 3s/step\n",
            "Epoch 7/40\n",
            "47/47 - 120s - loss: 0.8059 - accuracy: 0.7091 - val_loss: 0.7458 - val_accuracy: 0.7242 - 120s/epoch - 3s/step\n",
            "Epoch 8/40\n",
            "47/47 - 122s - loss: 0.7665 - accuracy: 0.7202 - val_loss: 0.8400 - val_accuracy: 0.6992 - 122s/epoch - 3s/step\n",
            "Epoch 9/40\n",
            "47/47 - 120s - loss: 0.7182 - accuracy: 0.7418 - val_loss: 1.3601 - val_accuracy: 0.5789 - 120s/epoch - 3s/step\n",
            "Epoch 10/40\n",
            "47/47 - 121s - loss: 0.6940 - accuracy: 0.7478 - val_loss: 0.6632 - val_accuracy: 0.7641 - 121s/epoch - 3s/step\n",
            "Epoch 11/40\n",
            "47/47 - 121s - loss: 0.6825 - accuracy: 0.7461 - val_loss: 0.9488 - val_accuracy: 0.6633 - 121s/epoch - 3s/step\n",
            "Epoch 12/40\n",
            "47/47 - 123s - loss: 0.6456 - accuracy: 0.7773 - val_loss: 0.5498 - val_accuracy: 0.8031 - 123s/epoch - 3s/step\n",
            "Epoch 13/40\n",
            "47/47 - 121s - loss: 0.6121 - accuracy: 0.7818 - val_loss: 0.6136 - val_accuracy: 0.7695 - 121s/epoch - 3s/step\n",
            "Epoch 14/40\n",
            "47/47 - 123s - loss: 0.6106 - accuracy: 0.7726 - val_loss: 0.5318 - val_accuracy: 0.8023 - 123s/epoch - 3s/step\n",
            "Epoch 15/40\n",
            "47/47 - 120s - loss: 0.5951 - accuracy: 0.7919 - val_loss: 0.6989 - val_accuracy: 0.7445 - 120s/epoch - 3s/step\n",
            "Epoch 16/40\n",
            "47/47 - 120s - loss: 0.5891 - accuracy: 0.7859 - val_loss: 0.5366 - val_accuracy: 0.7961 - 120s/epoch - 3s/step\n",
            "Epoch 17/40\n",
            "47/47 - 121s - loss: 0.5310 - accuracy: 0.8125 - val_loss: 0.6511 - val_accuracy: 0.7633 - 121s/epoch - 3s/step\n",
            "Epoch 18/40\n",
            "47/47 - 121s - loss: 0.5035 - accuracy: 0.8165 - val_loss: 0.7354 - val_accuracy: 0.7406 - 121s/epoch - 3s/step\n",
            "Epoch 19/40\n",
            "47/47 - 123s - loss: 0.5067 - accuracy: 0.8072 - val_loss: 0.5067 - val_accuracy: 0.8133 - 123s/epoch - 3s/step\n",
            "Epoch 20/40\n",
            "47/47 - 122s - loss: 0.5165 - accuracy: 0.8098 - val_loss: 0.5460 - val_accuracy: 0.8039 - 122s/epoch - 3s/step\n",
            "Epoch 21/40\n",
            "47/47 - 119s - loss: 0.4907 - accuracy: 0.8263 - val_loss: 0.9406 - val_accuracy: 0.6938 - 119s/epoch - 3s/step\n",
            "Epoch 22/40\n",
            "47/47 - 121s - loss: 0.5185 - accuracy: 0.8074 - val_loss: 0.4751 - val_accuracy: 0.8195 - 121s/epoch - 3s/step\n",
            "Epoch 23/40\n",
            "47/47 - 121s - loss: 0.4755 - accuracy: 0.8229 - val_loss: 0.4950 - val_accuracy: 0.8141 - 121s/epoch - 3s/step\n",
            "Epoch 24/40\n",
            "47/47 - 122s - loss: 0.4494 - accuracy: 0.8300 - val_loss: 0.4529 - val_accuracy: 0.8383 - 122s/epoch - 3s/step\n",
            "Epoch 25/40\n",
            "47/47 - 121s - loss: 0.4512 - accuracy: 0.8327 - val_loss: 0.9860 - val_accuracy: 0.7258 - 121s/epoch - 3s/step\n",
            "Epoch 26/40\n",
            "47/47 - 122s - loss: 0.4438 - accuracy: 0.8357 - val_loss: 0.6553 - val_accuracy: 0.7688 - 122s/epoch - 3s/step\n",
            "Epoch 27/40\n",
            "47/47 - 120s - loss: 0.4251 - accuracy: 0.8404 - val_loss: 0.5690 - val_accuracy: 0.7953 - 120s/epoch - 3s/step\n",
            "Epoch 28/40\n",
            "47/47 - 119s - loss: 0.4262 - accuracy: 0.8455 - val_loss: 0.4080 - val_accuracy: 0.8500 - 119s/epoch - 3s/step\n",
            "Epoch 29/40\n",
            "47/47 - 120s - loss: 0.4370 - accuracy: 0.8424 - val_loss: 0.3835 - val_accuracy: 0.8492 - 120s/epoch - 3s/step\n",
            "Epoch 30/40\n",
            "47/47 - 120s - loss: 0.4233 - accuracy: 0.8525 - val_loss: 0.3566 - val_accuracy: 0.8672 - 120s/epoch - 3s/step\n",
            "Epoch 31/40\n",
            "47/47 - 120s - loss: 0.3993 - accuracy: 0.8593 - val_loss: 0.4812 - val_accuracy: 0.8227 - 120s/epoch - 3s/step\n",
            "Epoch 32/40\n",
            "47/47 - 119s - loss: 0.4292 - accuracy: 0.8461 - val_loss: 0.4302 - val_accuracy: 0.8297 - 119s/epoch - 3s/step\n",
            "Epoch 33/40\n",
            "47/47 - 119s - loss: 0.4273 - accuracy: 0.8468 - val_loss: 0.3880 - val_accuracy: 0.8562 - 119s/epoch - 3s/step\n",
            "Epoch 34/40\n",
            "47/47 - 120s - loss: 0.3973 - accuracy: 0.8604 - val_loss: 0.4129 - val_accuracy: 0.8477 - 120s/epoch - 3s/step\n",
            "Epoch 35/40\n",
            "47/47 - 121s - loss: 0.3921 - accuracy: 0.8590 - val_loss: 0.4185 - val_accuracy: 0.8359 - 121s/epoch - 3s/step\n",
            "Epoch 36/40\n",
            "47/47 - 121s - loss: 0.3586 - accuracy: 0.8690 - val_loss: 0.3584 - val_accuracy: 0.8641 - 121s/epoch - 3s/step\n",
            "Epoch 37/40\n",
            "47/47 - 121s - loss: 0.4040 - accuracy: 0.8542 - val_loss: 0.3799 - val_accuracy: 0.8531 - 121s/epoch - 3s/step\n",
            "Epoch 38/40\n",
            "47/47 - 120s - loss: 0.3529 - accuracy: 0.8673 - val_loss: 0.3798 - val_accuracy: 0.8719 - 120s/epoch - 3s/step\n",
            "Epoch 39/40\n",
            "47/47 - 120s - loss: 0.3745 - accuracy: 0.8677 - val_loss: 0.3498 - val_accuracy: 0.8687 - 120s/epoch - 3s/step\n",
            "Epoch 40/40\n",
            "47/47 - 121s - loss: 0.3392 - accuracy: 0.8771 - val_loss: 0.4245 - val_accuracy: 0.8531 - 121s/epoch - 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "3xF0zGsvqMDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3fe376d-c1da-4fc4-9fa3-ace65862b935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 12s 541ms/step - loss: 0.4944 - accuracy: 0.8520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.494366317987442, 0.852011501789093]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}